import { salesAgentInvoke } from './agents/salesAgent.js';
import { GHLService } from './services/ghlService.js';
import { HumanMessage, AIMessage } from '@langchain/core/messages';
import { getCachedResponse } from './services/responseCache.js';
import { calendarCache } from './services/calendarCache.js';
import { messageCompressor } from './services/messageCompressor.js';
import { modelSelector } from './services/modelSelector.js';
import { toolResponseCompressor } from './services/toolResponseCompressor.js';
import { conversationTerminator } from './services/conversationTerminator.js';
import { Logger } from './services/logger.js';
import dotenv from 'dotenv';

dotenv.config();

const logger = new Logger('test-optimizations-detailed');

// Test configuration
const TEST_CONTACT_ID = process.env.TEST_CONTACT_ID || 'test-contact-123';

// Initialize services
const ghlService = new GHLService(
  process.env.GHL_API_KEY,
  process.env.GHL_LOCATION_ID
);

async function runDetailedTests() {
  console.log('\nüß™ DETAILED OPTIMIZATION TESTING\n');
  console.log('='.repeat(80));
  
  const testResults = [];
  
  // Test 1: Response Cache - Multiple scenarios
  console.log('\n1Ô∏è‚É£ TESTING RESPONSE CACHE IN DETAIL...\n');
  const cacheTests = [
    { input: 'hola', expected: true },
    { input: 'Hola', expected: true },
    { input: 'HOLA', expected: true },
    { input: 'buenos d√≠as', expected: true },
    { input: 'no me interesa', expected: true },
    { input: 'gracias', expected: true },
    { input: 'adi√≥s', expected: true },
    { input: 'random message xyz', expected: false }
  ];
  
  let cacheHits = 0;
  cacheTests.forEach(test => {
    const result = getCachedResponse(test.input, {});
    const passed = (result !== null) === test.expected;
    cacheHits += result ? 1 : 0;
    console.log(`   "${test.input}" ‚Üí ${result ? '‚úÖ CACHED' : '‚ùå NOT CACHED'} ${passed ? '(expected)' : '(UNEXPECTED!)'}`);
    if (result) {
      console.log(`      Response: "${result.substring(0, 60)}..."`);
    }
  });
  
  testResults.push({
    name: 'Response Cache',
    passed: cacheHits === 7,
    details: `${cacheHits}/7 expected cache hits`
  });
  
  // Test 2: Message Compression - Real scenario
  console.log('\n2Ô∏è‚É£ TESTING MESSAGE COMPRESSION...\n');
  const longConversation = [
    { role: 'human', content: 'Hola, soy Jaime Ortiz' },
    { role: 'assistant', content: '¬°Hola Jaime! Me da mucho gusto conocerte. Soy Mar√≠a de Outlet Media. Cu√©ntame, ¬øcu√°l es el principal desaf√≠o que enfrentas con tu negocio?' },
    { role: 'human', content: 'Tengo un restaurante mexicano y no puedo contestar todos los mensajes de WhatsApp de mis clientes' },
    { role: 'assistant', content: 'Entiendo perfectamente Jaime. Los restaurantes reciben muchos mensajes. ¬øCu√°l es tu meta principal? ¬øQu√© te gustar√≠a lograr con tu restaurante?' },
    { role: 'human', content: 'Quiero crecer mi negocio y tener m√°s clientes' },
    { role: 'assistant', content: 'Excelente meta Jaime. Para poder ayudarte mejor, ¬øcu√°l es tu presupuesto mensual aproximado para marketing y automatizaci√≥n?' },
    { role: 'human', content: 'Unos 500 d√≥lares mensuales' },
    { role: 'assistant', content: 'Perfecto Jaime, $500 mensuales es un excelente presupuesto. Para mostrarte los horarios disponibles, ¬øpodr√≠as compartirme tu email?' }
  ];
  
  const compressed = messageCompressor.compressHistory(longConversation);
  const originalSize = JSON.stringify(longConversation).length;
  const compressedSize = JSON.stringify(compressed).length;
  const compressionRatio = ((originalSize - compressedSize) / originalSize * 100).toFixed(1);
  
  console.log(`   Original size: ${originalSize} chars`);
  console.log(`   Compressed size: ${compressedSize} chars`);
  console.log(`   Compression ratio: ${compressionRatio}%`);
  console.log('\n   Compressed messages:');
  compressed.slice(0, -3).forEach((msg, idx) => {
    if (msg.compressed) {
      console.log(`   [${idx}] ${msg.content}`);
    }
  });
  
  testResults.push({
    name: 'Message Compression',
    passed: compressedSize < originalSize,
    details: `${compressionRatio}% compression achieved`
  });
  
  // Test 3: Model Selection - Multiple calls
  console.log('\n3Ô∏è‚É£ TESTING MODEL SELECTION...\n');
  const modelTests = [
    { message: 'Jaime', expectedModel: 'gpt-3.5-turbo' },
    { message: '500', expectedModel: 'gpt-3.5-turbo' },
    { message: 'si', expectedModel: 'gpt-3.5-turbo' },
    { message: 'Mi problema es que no puedo contestar mensajes y pierdo muchos clientes', expectedModel: 'gpt-4-turbo-preview' },
    { message: 'Quiero automatizar mi restaurante para crecer', expectedModel: 'gpt-4-turbo-preview' }
  ];
  
  modelTests.forEach(test => {
    const model = modelSelector.getModelForTool('extract_lead_info', { message: test.message });
    const modelName = model._kwargs?.model || 'unknown';
    const correct = modelName === test.expectedModel;
    console.log(`   "${test.message.substring(0, 40)}..." ‚Üí ${modelName} ${correct ? '‚úÖ' : '‚ùå'}`);
  });
  
  const modelStats = modelSelector.getStats();
  console.log(`\n   Model Selection Stats:`);
  console.log(`   - Total decisions: ${modelStats.totalDecisions}`);
  console.log(`   - GPT-3.5 usage: ${modelStats.gpt35UsagePercentage}`);
  console.log(`   - Cost savings: ${modelStats.costSavings}`);
  
  testResults.push({
    name: 'Model Selection',
    passed: modelStats.totalDecisions > 0,
    details: `${modelStats.gpt35UsagePercentage} using GPT-3.5`
  });
  
  // Test 4: Tool Response Compression
  console.log('\n4Ô∏è‚É£ TESTING TOOL RESPONSE COMPRESSION...\n');
  const toolResponses = [
    { 
      input: 'Extracted: {"name": "Jaime", "budget": 500, "problem": "no puedo contestar mensajes"}',
      expectedCompressed: '+name,budget,problem'
    },
    {
      input: 'Message sent successfully: "Hola Jaime, gracias por tu inter√©s en Outlet Media..."',
      expectedCompressed: 'SentOK'
    },
    {
      input: 'No new information extracted from message',
      expectedCompressed: 'NoInfo'
    },
    {
      input: 'Appointment booked successfully for Tuesday at 3:00 PM',
      expectedCompressed: 'BookedOK'
    },
    {
      input: 'Contact updated with tags: ["qualified-lead", "budget-300-plus"]',
      expectedCompressed: 'Tag:2'
    }
  ];
  
  let compressionPassed = 0;
  toolResponses.forEach(test => {
    const compressed = toolResponseCompressor.compress(test.input);
    const passed = compressed === test.expectedCompressed;
    compressionPassed += passed ? 1 : 0;
    console.log(`   "${test.input.substring(0, 50)}..."`);
    console.log(`      ‚Üí "${compressed}" ${passed ? '‚úÖ' : `‚ùå (expected: ${test.expectedCompressed})`}`);
  });
  
  const compressionStats = toolResponseCompressor.getStats();
  testResults.push({
    name: 'Tool Response Compression',
    passed: compressionPassed >= 4,
    details: `${compressionPassed}/5 tests passed, ${compressionStats.compressionRatio} overall`
  });
  
  // Test 5: Conversation Termination
  console.log('\n5Ô∏è‚É£ TESTING CONVERSATION TERMINATION...\n');
  const terminationScenarios = [
    {
      name: 'Appointment Booked',
      state: { appointmentBooked: true },
      lastMessage: 'Tu cita est√° confirmada para el martes a las 3:00 PM',
      expectedTerminate: true,
      expectedReason: 'appointment_booked'
    },
    {
      name: 'Under Budget',
      state: {},
      lastMessage: 'Mucho √©xito con tu negocio. Estamos aqu√≠ cuando est√©s listo.',
      expectedTerminate: true,
      expectedReason: 'terminalResponse'
    },
    {
      name: 'Calendar Waiting',
      state: { calendarShown: true },
      lastMessage: 'normal message',
      expectedTerminate: false,
      expectedReason: 'waiting_for_selection'
    },
    {
      name: 'User Rejection',
      userMessage: 'no me interesa',
      expectedTerminate: true
    }
  ];
  
  let terminationPassed = 0;
  terminationScenarios.forEach(scenario => {
    if (scenario.userMessage) {
      const result = conversationTerminator.isUserTermination(scenario.userMessage);
      const passed = result === scenario.expectedTerminate;
      terminationPassed += passed ? 1 : 0;
      console.log(`   ${scenario.name}: ${result ? 'TERMINATE' : 'CONTINUE'} ${passed ? '‚úÖ' : '‚ùå'}`);
    } else {
      const result = conversationTerminator.shouldTerminate(scenario.state, scenario.lastMessage);
      const passed = result.shouldTerminate === scenario.expectedTerminate;
      terminationPassed += passed ? 1 : 0;
      console.log(`   ${scenario.name}: ${result.shouldTerminate ? 'TERMINATE' : 'CONTINUE'} (${result.reason}) ${passed ? '‚úÖ' : '‚ùå'}`);
    }
  });
  
  testResults.push({
    name: 'Conversation Termination',
    passed: terminationPassed >= 3,
    details: `${terminationPassed}/4 scenarios correct`
  });
  
  // Test 6: Calendar Cache
  console.log('\n6Ô∏è‚É£ TESTING CALENDAR CACHE...\n');
  if (process.env.GHL_CALENDAR_ID) {
    // Initialize cache
    calendarCache.startAutoRefresh(process.env.GHL_CALENDAR_ID, ghlService);
    
    // Wait for initial load
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    // Test multiple cache hits
    console.log('   Testing cache performance:');
    const cacheTestTimes = [];
    
    for (let i = 0; i < 3; i++) {
      const start = Date.now();
      const slots = await calendarCache.getSlots();
      const time = Date.now() - start;
      cacheTestTimes.push(time);
      console.log(`   Attempt ${i + 1}: ${time}ms (${slots.length} slots)`);
    }
    
    const avgTime = cacheTestTimes.reduce((a, b) => a + b, 0) / cacheTestTimes.length;
    const cacheStats = calendarCache.getStats();
    
    console.log(`\n   Cache Stats:`);
    console.log(`   - Slots cached: ${cacheStats.slotCount}`);
    console.log(`   - Cache age: ${Math.floor(cacheStats.age / 1000)}s`);
    console.log(`   - Average access time: ${avgTime.toFixed(1)}ms`);
    
    calendarCache.stopAutoRefresh();
    
    testResults.push({
      name: 'Calendar Cache',
      passed: cacheStats.slotCount > 0 && avgTime < 50,
      details: `${cacheStats.slotCount} slots, ${avgTime.toFixed(1)}ms avg access`
    });
  }
  
  // Test 7: Integration Test - Simulated Conversation
  console.log('\n7Ô∏è‚É£ RUNNING FULL CONVERSATION SIMULATION...\n');
  const conversation = {
    messages: [],
    leadInfo: {},
    contactId: TEST_CONTACT_ID,
    stats: {
      llmCalls: 0,
      cachedResponses: 0,
      toolCalls: 0,
      tokensEstimated: 0
    }
  };
  
  const userMessages = [
    'hola',
    'Jaime',
    'tengo un restaurante y no puedo contestar mensajes',
    'crecer mi negocio',
    '500'
  ];
  
  for (const userMsg of userMessages) {
    console.log(`\n   üë§ User: "${userMsg}"`);
    
    // Check cache
    const cached = getCachedResponse(userMsg, conversation.leadInfo);
    if (cached) {
      console.log(`   üí® CACHED: "${cached.substring(0, 60)}..."`);
      conversation.stats.cachedResponses++;
      conversation.messages.push(new HumanMessage(userMsg));
      conversation.messages.push(new AIMessage(cached));
      continue;
    }
    
    // Check termination
    if (conversation.messages.length > 0) {
      const lastAI = conversation.messages.filter(m => m._getType?.() === 'ai').slice(-1)[0];
      if (lastAI) {
        const shouldStop = conversationTerminator.shouldTerminate(
          { 
            messages: conversation.messages,
            ...conversation.leadInfo
          }, 
          lastAI.content
        );
        if (shouldStop.shouldTerminate) {
          console.log(`   üõë TERMINATED: ${shouldStop.reason}`);
          break;
        }
      }
    }
    
    // Simulate agent processing
    console.log('   ü§ñ Processing with agent...');
    conversation.stats.llmCalls++;
    conversation.stats.toolCalls += 2; // extract_lead_info + send_message
    conversation.stats.tokensEstimated += 1500; // Rough estimate
    
    // Simulate responses
    conversation.messages.push(new HumanMessage(userMsg));
    if (userMsg === '500') {
      conversation.leadInfo = { name: 'Jaime', problem: 'no contest messages', goal: 'grow', budget: 500 };
      conversation.messages.push(new AIMessage('Perfecto Jaime. Para mostrarte horarios, necesito tu email.'));
    }
  }
  
  console.log('\n   üìä Conversation Stats:');
  console.log(`   - LLM Calls: ${conversation.stats.llmCalls}`);
  console.log(`   - Cached Responses: ${conversation.stats.cachedResponses}`);
  console.log(`   - Tool Calls: ${conversation.stats.toolCalls}`);
  console.log(`   - Estimated Tokens: ${conversation.stats.tokensEstimated}`);
  console.log(`   - Estimated Cost: $${(conversation.stats.tokensEstimated * 0.00001).toFixed(3)}`);
  
  testResults.push({
    name: 'Integration Test',
    passed: conversation.stats.cachedResponses > 0 && conversation.stats.llmCalls < 5,
    details: `${conversation.stats.cachedResponses} cached, ${conversation.stats.llmCalls} LLM calls`
  });
  
  // Final Summary
  console.log('\n' + '='.repeat(80));
  console.log('üìä DETAILED TEST RESULTS SUMMARY\n');
  
  let totalPassed = 0;
  testResults.forEach(result => {
    const status = result.passed ? '‚úÖ PASS' : '‚ùå FAIL';
    totalPassed += result.passed ? 1 : 0;
    console.log(`${result.name.padEnd(30)} ${status} - ${result.details}`);
  });
  
  const successRate = Math.round((totalPassed / testResults.length) * 100);
  console.log('\n' + '='.repeat(80));
  console.log(`OVERALL: ${totalPassed}/${testResults.length} tests passed (${successRate}% success rate)`);
  console.log('='.repeat(80));
  
  // Cost Analysis with Real Numbers
  console.log('\nüí∞ COST ANALYSIS WITH ACTUAL MEASUREMENTS:\n');
  
  const costBefore = {
    systemPrompt: 3300,
    avgToolCalls: 29,
    tokensPerConv: 15000,
    model: 'gpt-4',
    costPer1K: 0.03,
    total: 0.15
  };
  
  const costAfter = {
    systemPrompt: 550,
    avgToolCalls: conversation.stats.toolCalls,
    cachedResponses: conversation.stats.cachedResponses,
    tokensPerConv: conversation.stats.tokensEstimated,
    model: 'gpt-4-turbo-preview',
    costPer1K: 0.01,
    total: conversation.stats.tokensEstimated * 0.00001
  };
  
  console.log('BEFORE OPTIMIZATIONS:');
  console.log(`- System Prompt: ${costBefore.systemPrompt} tokens`);
  console.log(`- Tool Calls: ${costBefore.avgToolCalls}`);
  console.log(`- Total Tokens: ~${costBefore.tokensPerConv}`);
  console.log(`- Model: ${costBefore.model} ($${costBefore.costPer1K}/1K)`);
  console.log(`- Cost: $${costBefore.total}`);
  
  console.log('\nAFTER OPTIMIZATIONS:');
  console.log(`- System Prompt: ${costAfter.systemPrompt} tokens`);
  console.log(`- Tool Calls: ${costAfter.avgToolCalls}`);
  console.log(`- Cached Responses: ${costAfter.cachedResponses}`);
  console.log(`- Total Tokens: ~${costAfter.tokensPerConv}`);
  console.log(`- Model: ${costAfter.model} ($${costAfter.costPer1K}/1K)`);
  console.log(`- Cost: $${costAfter.total.toFixed(3)}`);
  
  const reduction = ((costBefore.total - costAfter.total) / costBefore.total * 100).toFixed(1);
  console.log(`\nüéâ TOTAL REDUCTION: ${reduction}% (from $${costBefore.total} to $${costAfter.total.toFixed(3)})`);
}

// Run detailed tests
runDetailedTests().catch(console.error);